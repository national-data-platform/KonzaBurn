{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55321893-b180-4a43-8c14-6b54619e86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d37c14",
   "metadata": {},
   "source": [
    "## Set `n_images` to a small number for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702e06b1-e198-455c-8b34-4b85aea3e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 12273"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bfbd0",
   "metadata": {},
   "source": [
    "## For reference: What is the image size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56417aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daef7395",
   "metadata": {},
   "source": [
    "## Fetch the weights of our trained ML encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f539e9-97e8-490a-9994-08613146dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"RESULTS\")\n",
    "kwargs = {\"weights_only\": True}\n",
    "\n",
    "def get_weights(path):\n",
    "    return torch.load(folder / path, **kwargs)[:n_images]\n",
    "\n",
    "int_rep = get_weights(\"internal_rep.pt\")\n",
    "rgb_int_rep = get_weights(\"rgb_internal_rep.pt\")\n",
    "ir_int_rep = get_weights(\"ir_internal_rep.pt\")\n",
    "\n",
    "print(\"int_rep.shape\", int_rep.shape)\n",
    "print(\"rgb_int_rep.shape\", rgb_int_rep.shape)\n",
    "print(\"ir_int_rep.shape\", ir_int_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b0adaf",
   "metadata": {},
   "source": [
    "## Concatenate the three weights into one big weight for TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08325ee-4dcf-4062-ae3e-634bb91c44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rep = torch.cat((int_rep, rgb_int_rep, ir_int_rep))\n",
    "print(\"all_rep.shape\", all_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2112f72",
   "metadata": {},
   "source": [
    "## Run TSNE on the concatenated weights\n",
    "## Warning: takes a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c07421-ceb2-4f7a-81d0-efb0fc4ea80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This takes 10 minutes on entire dataset (12273)\n",
    "emb_rep = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(all_rep)\n",
    "print(\"emb_rep.shape\", emb_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364cf25-3c6f-4af5-8020-5cf86f61966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(emb_rep[:, 0], emb_rep[:, 1], alpha=0.5, color='black', s=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7be0d",
   "metadata": {},
   "source": [
    "## Display combined, RGB, and IR separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d459b-da43-441b-a9d9-dda0e311ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = emb_rep[0*n_images:1*n_images]\n",
    "rgb = emb_rep[1*n_images:2*n_images]\n",
    "ir  = emb_rep[2*n_images:3*n_images]\n",
    "print(\"com.shape\", com.shape)\n",
    "print(\"rgb.shape\", rgb.shape)\n",
    "print(\"ir.shape\", ir.shape)\n",
    "plt.scatter(com[:,0], com[:,1], alpha=0.5, color=\"b\", s=5, label=f\"RGB + IR\")\n",
    "plt.scatter(rgb[:,0], rgb[:,1], alpha=0.5, color=\"r\", s=5, label=f\"RGB\")\n",
    "plt.scatter(ir[:,0],  ir[:,1],  alpha=0.5, color=\"g\", s=5, label=f\"IR\")\n",
    "plt.title(\"TSNE of internal representations\")\n",
    "plt.xlabel(\"Component 0\")\n",
    "plt.ylabel(\"Component 1\")\n",
    "plt.tick_params(top=True, right=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a4efb",
   "metadata": {},
   "source": [
    "## Add features based on the image filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3efb5f-e66c-4184-b466-e176668c1c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = folder / 'output.csv'\n",
    "prefix, postfix = len(\"sage_mobotix_cam_\"), len(\"20220415-000000\")\n",
    "df = pd.read_csv(output_path, header=None, names=['image_path', 'ignore_0', 'image_class', 'ignore_1'])\n",
    "df[\"image_name\"] = df[\"image_path\"].apply(lambda x: os.path.basename(x))\n",
    "df[\"image_date\"] = df[\"image_name\"].apply(lambda x: x[prefix:prefix+postfix])\n",
    "print(df[[\"image_name\", \"image_class\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b339c",
   "metadata": {},
   "source": [
    "## Let's focus on the RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3bca32-76b8-4604-8620-075a36998766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = com[:, 0]  # Get the first column of rgb (x-coordinates)\n",
    "#y = com[:, 1]  # Get the second column of rgb (y-coordinates)\n",
    "x = rgb[:, 0]  # Get the first column of rgb (x-coordinates)\n",
    "y = rgb[:, 1]  # Get the second column of rgb (y-coordinates)\n",
    "#x = ir[:, 0]  # Get the first column of rgb (x-coordinates)\n",
    "#y = ir[:, 1]  # Get the second column of rgb (y-coordinates)\n",
    "\n",
    "print(\"x.shape\", x.shape)\n",
    "print(\"y.shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a2dd4",
   "metadata": {},
   "source": [
    "## Let's highlight the different classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique classes\n",
    "classes = df['image_class'].unique()\n",
    "print(f\"Unique classes: {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164f2a4-77b3-4c91-8a39-a3b1886b56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "\n",
    "# Create a different color for each class\n",
    "fig = plt.figure()\n",
    "colors = ['black', 'r']\n",
    "for label in classes:\n",
    "    indices = label == df['image_class']\n",
    "    plt.scatter(x[indices], y[indices], c=colors[label], label=f'Class {label}', alpha=0.5, s=5)\n",
    "\n",
    "# Add text to the plot\n",
    "plt.title('Scatter Plot')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d5a8f",
   "metadata": {},
   "source": [
    "## Let's choose an image at random which has fire detected (`class==1`)\n",
    "## And let's compare with it's nearest neighbors in the embedded space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded63390-9de8-41d1-9349-e7ac1c446bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_closest = 4\n",
    "\n",
    "fire_indices = df[df['image_class'] == 1].index\n",
    "print(f\"fire_indices: {fire_indices}\")\n",
    "print(f\"fire_indices.shape: {fire_indices.shape}\")\n",
    "random_fire = random.choice(fire_indices)\n",
    "v = np.array([x[random_fire], y[random_fire]])\n",
    "\n",
    "# Step 1: Broadcast V to match the shape of C\n",
    "v_broadcasted = np.tile(v, (rgb.shape[0], 1))\n",
    "\n",
    "# Step 2: Calculate the Euclidean distances\n",
    "distances = np.linalg.norm(rgb - v_broadcasted, axis=1)\n",
    "\n",
    "# Step 3: Find the indices of the n_closest smallest distances\n",
    "closest_indices = np.argsort(distances)[:n_closest]\n",
    "\n",
    "print(closest_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d19e01",
   "metadata": {},
   "source": [
    "## Lets plot the images which are most similar in the internal representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a3954-68ba-4c2c-9104-da5842da5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a grid of subplots\n",
    "fig, axes = plt.subplots(figsize=(8, 3*nrows), nrows=n_closest)\n",
    "\n",
    "for i, index in enumerate(closest_indices):\n",
    "    print(f\"{df['image_path'][index]} is class={df['image_class'][index]}\")\n",
    "    image_path = df['image_path'][index]\n",
    "    image = mpimg.imread(\".\" + image_path)\n",
    "    title = f\"{df['image_date'][index]}, Class={df['image_class'][index]}\"\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(title)\n",
    "\n",
    "# Display the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3fce8",
   "metadata": {},
   "source": [
    "## Let's highlight the nearest neighbors on the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2bf81-fe06-4aae-9521-218b74ba9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with a different color for each class\n",
    "fig = plt.figure()\n",
    "for label in classes:\n",
    "    indices = label == df['image_class']\n",
    "    plt.scatter(x[indices], y[indices], c=colors[label], label=f'Class {label}', alpha=0.5, s=5)\n",
    "\n",
    "# Highlight the closest points\n",
    "plt.scatter(x[closest_indices], y[closest_indices], c='blue', alpha=0.5, s=15)\n",
    "\n",
    "# Add text to the plot\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31d3bc-4bce-4c90-8486-dfa00c162a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = df['image_class'].sum() / len(df['image_class'])\n",
    "print(f\"Fraction of fire detection: {fraction:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac3441-5271-4e51-8a4a-0b5038130b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
