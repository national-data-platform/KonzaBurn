{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dba8178",
   "metadata": {},
   "source": [
    "# Exploring the internal representation of images from Konza burn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55321893-b180-4a43-8c14-6b54619e86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d37c14",
   "metadata": {},
   "source": [
    "## Set `n_images` to a small number for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702e06b1-e198-455c-8b34-4b85aea3e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 12273"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bfbd0",
   "metadata": {},
   "source": [
    "## For reference: What is the image size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56417aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path(\"./images\")\n",
    "random_image_path = random.choice(list(image_dir.glob(\"*\")))\n",
    "print(f\"A randomly chosen image: {random_image_path}\")\n",
    "fig, ax = plt.subplots()\n",
    "random_image = mpimg.imread(random_image_path)\n",
    "print(f\"Image shape: {random_image.shape}\")\n",
    "ax.imshow(random_image)\n",
    "ax.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef7395",
   "metadata": {},
   "source": [
    "## Fetch the weights of our trained ML encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f539e9-97e8-490a-9994-08613146dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"./RESULTS\")\n",
    "kwargs = {\"weights_only\": True}\n",
    "\n",
    "def get_weights(path):\n",
    "    return torch.load(folder / path, **kwargs)[:n_images]\n",
    "\n",
    "int_rep = get_weights(\"internal_rep.pt\")\n",
    "rgb_int_rep = get_weights(\"rgb_internal_rep.pt\")\n",
    "ir_int_rep = get_weights(\"ir_internal_rep.pt\")\n",
    "\n",
    "print(\"int_rep.shape\", int_rep.shape)\n",
    "print(\"rgb_int_rep.shape\", rgb_int_rep.shape)\n",
    "print(\"ir_int_rep.shape\", ir_int_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b0adaf",
   "metadata": {},
   "source": [
    "## Concatenate the three weights into one big weight for TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08325ee-4dcf-4062-ae3e-634bb91c44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rep = torch.cat((int_rep, rgb_int_rep, ir_int_rep))\n",
    "print(\"all_rep.shape\", all_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2112f72",
   "metadata": {},
   "source": [
    "## Run TSNE on the concatenated weights\n",
    "## Warning: takes a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c07421-ceb2-4f7a-81d0-efb0fc4ea80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emb_rep = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(all_rep)\n",
    "print(\"emb_rep.shape\", emb_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364cf25-3c6f-4af5-8020-5cf86f61966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(emb_rep[:, 0], emb_rep[:, 1], alpha=0.5, color='black', s=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7be0d",
   "metadata": {},
   "source": [
    "## Display combined, RGB, and IR separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d459b-da43-441b-a9d9-dda0e311ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = emb_rep[0*n_images:1*n_images]\n",
    "rgb = emb_rep[1*n_images:2*n_images]\n",
    "ir  = emb_rep[2*n_images:3*n_images]\n",
    "print(\"com.shape\", com.shape)\n",
    "print(\"rgb.shape\", rgb.shape)\n",
    "print(\"ir.shape\", ir.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f582fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(com[:,0], com[:,1], alpha=0.5, color=\"b\", s=5, label=f\"RGB + IR\")\n",
    "plt.scatter(rgb[:,0], rgb[:,1], alpha=0.5, color=\"r\", s=5, label=f\"RGB\")\n",
    "plt.scatter(ir[:,0],  ir[:,1],  alpha=0.5, color=\"g\", s=5, label=f\"IR\")\n",
    "plt.title(\"TSNE of internal representations\")\n",
    "plt.xlabel(\"Component 0\")\n",
    "plt.ylabel(\"Component 1\")\n",
    "plt.tick_params(top=True, right=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a4efb",
   "metadata": {},
   "source": [
    "## Add features based on the image filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3efb5f-e66c-4184-b466-e176668c1c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = folder / 'output.csv'\n",
    "prefix, postfix = len(\"sage_mobotix_cam_\"), len(\"20220415-000000\")\n",
    "df = pd.read_csv(output_path, header=None, names=['image_path', 'ignore_0', 'image_class', 'ignore_1'])\n",
    "df[\"image_name\"] = df[\"image_path\"].apply(lambda x: os.path.basename(x))\n",
    "df[\"image_date\"] = df[\"image_name\"].apply(lambda x: x[prefix:prefix+postfix])\n",
    "print(df[[\"image_name\", \"image_class\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b339c",
   "metadata": {},
   "source": [
    "## Let's focus on the RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3bca32-76b8-4604-8620-075a36998766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = com[:, 0]  # Get the first column of rgb (x-coordinates)\n",
    "#y = com[:, 1]  # Get the second column of rgb (y-coordinates)\n",
    "x = rgb[:, 0]  # Get the first column of rgb (x-coordinates)\n",
    "y = rgb[:, 1]  # Get the second column of rgb (y-coordinates)\n",
    "#x = ir[:, 0]  # Get the first column of rgb (x-coordinates)\n",
    "#y = ir[:, 1]  # Get the second column of rgb (y-coordinates)\n",
    "\n",
    "print(\"x.shape\", x.shape)\n",
    "print(\"y.shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a2dd4",
   "metadata": {},
   "source": [
    "## Let's highlight the different classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique classes\n",
    "classes = df['image_class'].unique()\n",
    "print(f\"Unique classes: {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164f2a4-77b3-4c91-8a39-a3b1886b56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a different color for each class\n",
    "fig = plt.figure()\n",
    "colors = ['black', 'r']\n",
    "for label in classes:\n",
    "    indices = label == df['image_class']\n",
    "    plt.scatter(x[indices], y[indices], c=colors[label], label=f'Class {label}', alpha=0.5, s=5)\n",
    "\n",
    "# Add text to the plot\n",
    "plt.title(\"TSNE of internal representations\")\n",
    "plt.xlabel(\"Component 0\")\n",
    "plt.ylabel(\"Component 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d5a8f",
   "metadata": {},
   "source": [
    "## Let's choose an image at random which has fire detected (`class==1`)\n",
    "## And let's compare with it's nearest neighbors in the embedded space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded63390-9de8-41d1-9349-e7ac1c446bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_closest = 4\n",
    "\n",
    "fire_indices = df[df['image_class'] == 1].index\n",
    "print(f\"fire_indices.shape: {fire_indices.shape}\")\n",
    "random_fire = random.choice(fire_indices)\n",
    "v = np.array([x[random_fire], y[random_fire]])\n",
    "print(f\"Randomly chose fire image with coordinates: {v}\")\n",
    "\n",
    "# Step 1: Broadcast V to match the shape of C\n",
    "v_broadcasted = np.tile(v, (rgb.shape[0], 1))\n",
    "\n",
    "# Step 2: Calculate the Euclidean distances\n",
    "distances = np.linalg.norm(rgb - v_broadcasted, axis=1)\n",
    "\n",
    "# Step 3: Find the indices of the n_closest smallest distances\n",
    "closest_indices = np.argsort(distances)[:n_closest]\n",
    "\n",
    "print(f\"Closest indices: {closest_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d19e01",
   "metadata": {},
   "source": [
    "## Let's plot the images which are most similar in the internal representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a3954-68ba-4c2c-9104-da5842da5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a grid of subplots\n",
    "fig, axes = plt.subplots(figsize=(8, 3*n_closest), nrows=n_closest)\n",
    "\n",
    "for i, index in enumerate(closest_indices):\n",
    "    print(f\"{df['image_path'][index]} is class={df['image_class'][index]}\")\n",
    "    image_path = df['image_path'][index]\n",
    "    image = mpimg.imread(image_dir / os.path.basename(image_path))\n",
    "    title = f\"{df['image_date'][index]}, Class={df['image_class'][index]}\"\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(title)\n",
    "\n",
    "# Display the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3fce8",
   "metadata": {},
   "source": [
    "## Let's highlight the nearest neighbors on the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2bf81-fe06-4aae-9521-218b74ba9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with a different color for each class\n",
    "fig = plt.figure()\n",
    "for label in classes:\n",
    "    indices = label == df['image_class']\n",
    "    plt.scatter(x[indices], y[indices], c=colors[label], label=f'Class {label}', alpha=0.5, s=5)\n",
    "\n",
    "# Highlight the closest points\n",
    "plt.scatter(x[closest_indices], y[closest_indices], label=\"Neighbors\", c='blue', alpha=0.5, s=15)\n",
    "\n",
    "# Add text to the plot\n",
    "plt.title(\"TSNE of internal representations\")\n",
    "plt.xlabel(\"Component 0\")\n",
    "plt.ylabel(\"Component 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc219e1",
   "metadata": {},
   "source": [
    "## For reference: what fraction of images have fire detected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31d3bc-4bce-4c90-8486-dfa00c162a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = df['image_class'].sum() / len(df['image_class'])\n",
    "print(f\"Fraction of fire detection: {fraction:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
